{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "import time\n",
    "import sys\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(259431, 26)\n"
     ]
    }
   ],
   "source": [
    "train_fname = '../data/train_transformed_3.csv'\n",
    "test_fname = '../data/test_transformed_2.csv'\n",
    "df = pd.read_csv(train_fname, sep=';')\n",
    "df_test = pd.read_csv(test_fname, sep=';')\n",
    "f_con = ['INV_NB',\n",
    "        'INV_NB_PAYS','INV_NB_TYPE','cited_n','cited_age_min','cited_age_median','cited_age_max','cited_age_mean',\n",
    "        'cited_age_std','NB_BACKWARD_NPL','NB_BACKWARD_XY','NB_BACKWARD_I','NB_BACKWARD_AUTRE','NB_BACKWARD_PL',\n",
    "        'NB_BACKWARD','pct_NB_IPC','pct_NB_IPC_LY','oecd_NB_ROOT_CLASSES','oecd_NB_BACKWARD_PL','oecd_NB_BACKWARD_NPL',\n",
    "        'IDX_ORIGIN','IDX_RADIC','PRIORITY_MONTH','FILING_MONTH','PUBLICATION_MONTH','BEGIN_MONTH']\n",
    "(n_samples,n_variables) = (df.shape[0],len(f_con))\n",
    "\n",
    "#df = df.reindex(np.random.permutation(df.index));\n",
    "X_train1 = df[f_con].values\n",
    "y_train = df.VARIABLE_CIBLE == 'GRANTED'\n",
    "X_test1 = df_test[f_con].values\n",
    "imputer = Imputer()\n",
    "# Imputer permet de combler les trous quand des données manquent. Par défaut il prend la moyenne de la dernière donnée vue\n",
    "# et de la prochaine. Ces données ne sont donc pas normalisées.\n",
    "X_train1 = imputer.fit_transform(X_train1)\n",
    "X_test1 = imputer.fit_transform(X_test1)\n",
    "# Normalisation des features.\n",
    "scale(X_train1,copy=False);\n",
    "scale(X_test1,copy=False);\n",
    "print(X_train1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.concatenate((X_train1,X_test1), axis=0)\n",
    "scale(X, copy=False);\n",
    "pca = PCA(n_components=26)\n",
    "X = pca.fit_transform(X)\n",
    "X_train = X[0:X_train1.shape[0]]\n",
    "X_test = X[X_train1.shape[0]:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233.025444031\n"
     ]
    }
   ],
   "source": [
    "n_taken = n_samples\n",
    "start = time.time()\n",
    "model = make_pipeline(PolynomialFeatures(degree=2, include_bias = False), LogisticRegression(C=0.014))\n",
    "model.fit(X_train[0:n_taken], y_train[0:n_taken])\n",
    "print(time.time() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (optimiste) sur le train : 0.620966543456\n",
      "0.606955221234\n"
     ]
    }
   ],
   "source": [
    "y_pred_train = model.predict_proba(X_train)[:, 1]\n",
    "print('Score (optimiste) sur le train : %s' % roc_auc_score(y_train, y_pred_train))\n",
    "print(model.score(X_train[0:n_taken], y_train[0:n_taken]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# last : 0.623626227995\n",
    "# 0.572773523603"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#n_taken = n_samples\n",
    "#nb_thread = 4\n",
    "#model = make_pipeline(PolynomialFeatures(degree=2, include_bias = False), LogisticRegression())\n",
    "#pf = PolynomialFeatures(degree = 2, include_bias = False)\n",
    "#X_train_poly = pf.fit_transform(X_train)\n",
    "#X_test_poly = pf.fit_transform(X_test)\n",
    "#model.fit(X_train[0:n_taken], y_train[0:n_taken]);\n",
    "#parameters = {'C':[0.1,0.2,0.3, 0.4,0.5,0.6,0.7,0.8,0.9,1.]}\n",
    "#def scorer(estimator, X, y):\n",
    "#    return roc_auc_score(y, estimator.predict_proba(X)[:,1])\n",
    "#lr = LogisticRegression()\n",
    "#clf = GridSearchCV(lr, parameters, scorer, n_jobs = nb_thread)\n",
    "#clf.fit(X_train_poly[0:n_taken],y_train[0:n_taken])\n",
    "#y_pred_train = clf.predict_proba(X_train_poly)[:, 1]\n",
    "#print('Score (optimiste) sur le train : %s' % roc_auc_score(y_train, y_pred_train))\n",
    "#print(clf.score(X_train_poly[0:n_taken], y_train_poly[0:n_taken]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=y_pred_train, columns=['VARIABLE_CIBLE']).to_csv(path_or_buf='../y_trained/cont_reglogpoly_2_27.02.26.txt', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../trained_models/cont_relogpoly_2_27_02_16.pkl',\n",
       " '../trained_models/cont_relogpoly_2_27_02_16.pkl_01.npy',\n",
       " '../trained_models/cont_relogpoly_2_27_02_16.pkl_02.npy',\n",
       " '../trained_models/cont_relogpoly_2_27_02_16.pkl_03.npy']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "joblib.dump(model, '../trained_models/cont_relogpoly_2_27_02_16.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Score (optimiste) sur le train : %s' % roc_auc_score(y_train, y_pred_train))\n",
    "print(model.score(X_train[0:n_taken], y_train[0:n_taken]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.591120640085\n",
    "# C = 0.014"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Démarche :\n",
    "#### Le kernel explose si on utilise les 28 dimensions avec tout les samples :\n",
    "#### 259431*29*30/2 = 112,852,485 floats codés sur 64 bits = 8 bytes.\n",
    "#### On a donc réduit la dimension via PCA jusqu'à ce que le kernel n'explose plus, ce qui nous amené à 25 composantes :\n",
    "####  259431*25*26/2 = 84,315,075.\n",
    "#### Ensuite on a cherché le meilleur C pour 25 dimensions. Il faudrait faire une propre CV avec tout les samples et attendre un moment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Application au test set et sauvegarde de la soumission correspondante.\n",
    "y_pred = model.predict_proba(X_test)[:, 1]\n",
    "np.savetxt('../subs/continue_polylogreg3.txt', y_pred, fmt='%s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(roc_auc_score(y_train, y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_train,y_pred_train)\n",
    "plt.plot([0,1],[0,1])\n",
    "plt.plot(fpr, tpr, lw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train - y_pred_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(abs(y_train - y_pred_train) > 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
