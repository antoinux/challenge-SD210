{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SD210 - Challenge\n",
    "## TURQUETIL Antoine\n",
    "## Récaputulatif de la méthode\n",
    "\n",
    "Tout le travail a été réalisé avec scikit-learn sous python.\n",
    "\n",
    "### I. Analyse des variables explicatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première chose à faire était de regarder plus ou moins en détail quelles variables étaient inutiles. En particulier certaines variables comme 'cited_nmiss' ou 'cited_age_std' ont été rejetées comme manifestement trop peu explicatives. 'cited_nmiss' ne prend en particulier qu'une valeur et est absente d'environ 60% des données. La plupart des variables ont toutefois été gardées même si certaines étaient doûteuses, dans l'espoir de gagner quelque points.\n",
    "\n",
    "Une approche de type PCA a été tentée pour tenter de réduire la dimension du problème, mais on perdait trop en performances. De même pour l'évaluation d'importance des features avec les random forests.\n",
    "\n",
    "L'analyse met aussi au jour la quantité importante de \"trous\" dans les données. On pourrait tenter d'inférer les données manquantes à partir des autres pour obtenir un dataset de meilleure qualité et augmenter la fiabilité de la de la prédiction. Cette idée n'a pas abouti pour le résultat final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Distinction catégorie/continuité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme c'était conseillé dans starting kit, on s'est assez vite penché sur la nature hétérogène des features : certaines sont catégorielles quand les autres sont continues. Il conviendra donc de les traiter différemment.\n",
    "\n",
    "En premier lieu, on a cherché à entraîner un modèle pour les catégories et un autre pour les continues, avant de les \"recoller\". Régression logistique (polynomiale), KNN, SVM,... Beaucoup de modèles ont été expérimentés.\n",
    "\n",
    "La partie critique de cette manière d'aborder le problème est le recollement :\n",
    "\n",
    "- Le modèle 1 donne Y1 (vecteur à valeurs de 0 à 1 contenant les prédictions en probabilité) à partir de X1.\n",
    "- Le modèle 2 donne Y2 à partir de X2.\n",
    "- Le modèle 3 donne Y3 (réponse finale) à partir de Y1 et Y2.\n",
    "\n",
    "Le modèle 3 est donc un problème de classification à deux variables. On a choisi initialement d'utiliser une régression logistique polynomiale :\n",
    "\n",
    "##### insérer graphe de la méson\n",
    "\n",
    "Il se trouve que cette méthode n'a pas donné un score aussi élevé que d'autres méthodes plus simples à mettre en oeuvre. C'est à dire utiliser RandomForestClassifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Les forêts aléatoires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Ensuite, on a essayé les forêts aléatoires. L'avantage de ce modèle est de pouvoir gérer simultanément des variables continues et catégorielles. Toutefois, si l'algorithme peut directement s'appliquer aux données continues, la question se pose pour les données catégorielles.\n",
    "\n",
    "Pour des raisons évidentes de performance, il est tout d'abord nécessaire d'encoder les différentes valeurs prises par une variable catégorielles par des nombres (utilisation en particulier de LabelEncoder de sklearn).\n",
    "\n",
    "En effet, les arbres de décisions fonctionnent en split, c'est à dire qu'ils séparent successivement les données sur la base d'un ordre total. Or, les données catégorielles sous maintenant sous forme numérique mais aucun ordre total ne peut être induit dessus, ce qui risque donc de tromper l'algorithme. Toutefois, de nombreuses sources sur le net semblent signaler que RandomForestClassifier est capable d'apprendre de lui-même"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
